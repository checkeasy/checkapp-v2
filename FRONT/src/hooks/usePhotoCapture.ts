import { useState, useCallback } from 'react';
import { CapturedPhoto, UsePhotoCaptureResult } from '@/types/photoCapture';
import { resizeImage, detectBrowser, getDeviceOrientation } from '@/utils/cameraPolyfills';
import { environment } from '@/config/environment';

function generateId(): string {
  return Math.random().toString(36).slice(2) + Math.random().toString(36).slice(2);
}

// üîç D√âTECTION DE FLOU : Fonction pour analyser la nettet√© de l'image (Laplacien 2D am√©lior√©)
function detectBlur(canvas: HTMLCanvasElement): { isBlurry: boolean; blurScore: number; stats: any } {
  try {
    if (!environment.BLUR_DETECTION_ENABLED) {
      return { isBlurry: false, blurScore: 0, stats: { disabled: true } };
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) return { isBlurry: false, blurScore: 0, stats: { error: 'no_context' } };

    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const data = imageData.data;
    const width = canvas.width;
    const height = canvas.height;

    // üîß Param√®tres configurables
    const step = environment.BLUR_ANALYSIS_STEP;
    const margin = environment.BLUR_EDGE_MARGIN;
    const threshold = environment.BLUR_THRESHOLD;
    const minVariance = environment.BLUR_MIN_VARIANCE;

    // Convertir en niveaux de gris
    const grayData: number[] = [];
    for (let i = 0; i < data.length; i += 4) {
      const r = data[i];
      const g = data[i + 1];
      const b = data[i + 2];
      const gray = 0.299 * r + 0.587 * g + 0.114 * b; // Formule standard de luminance
      grayData.push(gray);
    }

    // üìä Calculer le Laplacien 2D (convolution avec kernel)
    let laplacianSum = 0;
    let pixelCount = 0;
    let maxLaplacian = 0;

    // Kernel Laplacien 3x3 standard
    const kernel = [
      [0, -1, 0],
      [-1, 4, -1],
      [0, -1, 0]
    ];

    // Analyser la zone centrale (ignorer les bords)
    const startX = Math.floor(margin / step);
    const endX = Math.floor((width - margin) / step);
    const startY = Math.floor(margin / step);
    const endY = Math.floor((height - margin) / step);

    for (let y = startY; y < endY; y += step) {
      for (let x = startX; x < endX; x += step) {
        // V√©rifier qu'on ne sort pas des limites
        if (y < 1 || y >= height - 1 || x < 1 || x >= width - 1) continue;

        let laplacian = 0;
        // Appliquer le kernel Laplacien
        for (let ky = -1; ky <= 1; ky++) {
          for (let kx = -1; kx <= 1; kx++) {
            const idx = (y + ky) * width + (x + kx);
            if (idx >= 0 && idx < grayData.length) {
              laplacian += grayData[idx] * kernel[ky + 1][kx + 1];
            }
          }
        }

        laplacian = Math.abs(laplacian);
        laplacianSum += laplacian * laplacian;
        maxLaplacian = Math.max(maxLaplacian, laplacian);
        pixelCount++;
      }
    }

    // üìä Calculer le score de nettet√©
    const blurScore = pixelCount > 0 ? Math.sqrt(laplacianSum / pixelCount) : 0;

    // üîß D√©terminer si l'image est floue
    // Une image nette a un score Laplacien √©lev√©
    const isBlurry = blurScore < threshold && maxLaplacian < minVariance;

    // üìà Statistiques d√©taill√©es
    const stats = {
      blurScore: parseFloat(blurScore.toFixed(2)),
      maxLaplacian: parseFloat(maxLaplacian.toFixed(2)),
      pixelCount,
      threshold,
      minVariance,
      isBlurry,
      confidence: Math.min(100, Math.max(0, (blurScore / threshold) * 100))
    };

    console.log('üîç Analyse de flou am√©lior√©e:', stats);

    return { isBlurry, blurScore, stats };
  } catch (error) {
    console.warn('‚ö†Ô∏è Erreur lors de la d√©tection de flou:', error);
    return { isBlurry: false, blurScore: 0, stats: { error: String(error) } };
  }
}

// üîß AM√âLIORATION QUALIT√â : Fonction pour appliquer sharpening, contraste et optimisation d'exposition
function applyImageEnhancements(ctx: CanvasRenderingContext2D, canvas: HTMLCanvasElement): void {
  try {
    // R√©cup√©rer les donn√©es d'image
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const data = imageData.data;

    // üìä Analyser l'exposition (luminosit√© moyenne)
    let totalBrightness = 0;
    for (let i = 0; i < data.length; i += 4) {
      const r = data[i];
      const g = data[i + 1];
      const b = data[i + 2];
      totalBrightness += (r + g + b) / 3;
    }
    const avgBrightness = totalBrightness / (data.length / 4);

    // üîß Calculer le facteur d'ajustement d'exposition
    // Si trop sombre (< 80), augmenter ; si trop clair (> 200), diminuer
    let exposureAdjustment = 1;
    if (avgBrightness < 80) {
      exposureAdjustment = 1.15; // +15% de luminosit√©
    } else if (avgBrightness > 200) {
      exposureAdjustment = 0.95; // -5% de luminosit√©
    }

    // üîß Appliquer sharpening SUBTIL et MOINS de contraste
    const sharpenStrength = 0.7; // Sharpening augment√© mais subtil
    const contrastStrength = 1.05; // Contraste R√âDUIT (1.05 au lieu de 1.2)

    for (let i = 0; i < data.length; i += 4) {
      let r = data[i];
      let g = data[i + 1];
      let b = data[i + 2];

      // 1Ô∏è‚É£ Appliquer l'ajustement d'exposition
      r = Math.min(255, r * exposureAdjustment);
      g = Math.min(255, g * exposureAdjustment);
      b = Math.min(255, b * exposureAdjustment);

      // 2Ô∏è‚É£ Appliquer le contraste L√âGER (augmente tr√®s peu les diff√©rences)
      const centerValue = 128;
      r = centerValue + (r - centerValue) * contrastStrength;
      g = centerValue + (g - centerValue) * contrastStrength;
      b = centerValue + (b - centerValue) * contrastStrength;

      // 3Ô∏è‚É£ Appliquer le sharpening SUBTIL (augmente les d√©tails fins)
      // Technique de sharpening par augmentation de contraste local MOD√âR√âE
      const sharpenFactor = 1 + (sharpenStrength * 0.3); // R√©duire l'impact du sharpening
      r = Math.min(255, Math.max(0, r * sharpenFactor - (centerValue * sharpenStrength * 0.2)));
      g = Math.min(255, Math.max(0, g * sharpenFactor - (centerValue * sharpenStrength * 0.2)));
      b = Math.min(255, Math.max(0, b * sharpenFactor - (centerValue * sharpenStrength * 0.2)));

      // Clamp values
      data[i] = Math.round(Math.min(255, Math.max(0, r)));
      data[i + 1] = Math.round(Math.min(255, Math.max(0, g)));
      data[i + 2] = Math.round(Math.min(255, Math.max(0, b)));
    }

    // Remettre les donn√©es modifi√©es sur le canvas
    ctx.putImageData(imageData, 0, 0);

    console.log('‚ú® Am√©liorations appliqu√©es:', {
      avgBrightness: avgBrightness.toFixed(1),
      exposureAdjustment: (exposureAdjustment * 100).toFixed(0) + '%',
      sharpenStrength,
      contrastStrength
    });
  } catch (error) {
    console.warn('‚ö†Ô∏è Erreur lors de l\'application des am√©liorations:', error);
  }
}

export function usePhotoCapture(pieceId: string): UsePhotoCaptureResult {
  const [capturedPhotos, setCapturedPhotos] = useState<Map<string, CapturedPhoto>>(new Map());

  const capturePhoto = useCallback(async (
    video: HTMLVideoElement,
    referenceId: string
  ): Promise<CapturedPhoto> => {
    return new Promise((resolve, reject) => {
      try {
        console.log('üì∏ D√©but de capture pour r√©f√©rence:', referenceId);

        // üì± D√©tecter le navigateur pour optimisations sp√©cifiques
        const browser = detectBrowser();

        // Cr√©er un canvas pour la capture
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d', {
          // ‚úÖ Optimisation m√©moire pour mobile
          alpha: false,
          willReadFrequently: false
        });

        if (!ctx) {
          throw new Error('Impossible de cr√©er le contexte canvas');
        }

        // Obtenir les dimensions r√©elles de la vid√©o
        const videoWidth = video.videoWidth || 1920;
        const videoHeight = video.videoHeight || 1440;

        // ‚úÖ FIX ROTATION BUG: D√©tecter l'orientation de l'appareil
        const deviceOrientation = getDeviceOrientation();

        // Ajuster les dimensions du canvas selon l'orientation
        // Pour les rotations de 90¬∞ ou 270¬∞, inverser largeur et hauteur
        const needsRotation = deviceOrientation === 90 || deviceOrientation === -90 || deviceOrientation === 270;

        if (needsRotation) {
          canvas.width = videoHeight;
          canvas.height = videoWidth;
        } else {
          canvas.width = videoWidth;
          canvas.height = videoHeight;
        }

        console.log('üìê Dimensions capture:', {
          width: videoWidth,
          height: videoHeight,
          deviceOrientation,
          canvasWidth: canvas.width,
          canvasHeight: canvas.height,
          browser: browser.isIOS ? 'iOS' : browser.isAndroid ? 'Android' : 'Desktop'
        });

        // ‚úÖ FIX MIRROR BUG: Ne pas appliquer de transformation miroir
        // Le preview vid√©o est mirrored pour l'UX (scaleX(-1) en CSS)
        // Mais la photo captur√©e doit √™tre dans l'orientation r√©elle (non-mirrored)

        // ‚úÖ FIX ROTATION BUG: Appliquer la rotation selon l'orientation de l'appareil
        if (needsRotation) {
          // Centrer le point de rotation
          ctx.translate(canvas.width / 2, canvas.height / 2);

          // Appliquer la rotation
          if (deviceOrientation === 90 || deviceOrientation === -270) {
            ctx.rotate(90 * Math.PI / 180);
          } else if (deviceOrientation === -90 || deviceOrientation === 270) {
            ctx.rotate(-90 * Math.PI / 180);
          } else if (deviceOrientation === 180 || deviceOrientation === -180) {
            ctx.rotate(180 * Math.PI / 180);
          }

          // Repositionner pour dessiner
          ctx.translate(-videoWidth / 2, -videoHeight / 2);
        }

        // Dessiner la frame vid√©o sur le canvas
        ctx.drawImage(video, 0, 0, videoWidth, videoHeight);

        // ‚úÖ Optimisation m√©moire : Redimensionner si trop grand
        // üîß AUGMENTATION QUALIT√â : R√©solution max augment√©e pour meilleure analyse IA
        const maxWidth = 3840;  // 4K width
        const maxHeight = 2880; // 4K height
        const optimizedCanvas = resizeImage(canvas, maxWidth, maxHeight);

        console.log('üìè Dimensions optimis√©es:', {
          original: `${videoWidth}x${videoHeight}`,
          optimized: `${optimizedCanvas.width}x${optimizedCanvas.height}`,
          reduction: Math.round((1 - (optimizedCanvas.width * optimizedCanvas.height) / (videoWidth * videoHeight)) * 100) + '%'
        });

        // üîç D√âTECTION DE FLOU : Analyser la nettet√© avant d'am√©liorer
        const { isBlurry, blurScore, stats } = detectBlur(optimizedCanvas);

        // üîß AM√âLIORATION QUALIT√â : Appliquer sharpening et optimisation d'exposition
        applyImageEnhancements(ctx, optimizedCanvas);

        // Convertir en blob avec qualit√© adapt√©e au navigateur
        // üîß AUGMENTATION QUALIT√â : Qualit√© JPEG augment√©e √† 0.98 pour meilleure analyse IA
        const quality = 0.98; // Qualit√© maximale pour analyse IA

        optimizedCanvas.toBlob(async (blob) => {
          if (!blob) {
            reject(new Error('Impossible de cr√©er le blob'));
            return;
          }

          try {
            console.log('üíæ Taille du blob:', (blob.size / 1024 / 1024).toFixed(2), 'MB');

            // ‚úÖ V√©rification taille maximale (15MB pour accommoder la meilleure qualit√©)
            // üîß AUGMENTATION QUALIT√â : Limite augment√©e pour photos haute qualit√©
            if (blob.size > 15 * 1024 * 1024) {
              console.warn('‚ö†Ô∏è Image trop volumineuse, compression suppl√©mentaire...');
              // R√©duire encore la qualit√© si n√©cessaire
              optimizedCanvas.toBlob(async (compressedBlob) => {
                if (compressedBlob) {
                  blob = compressedBlob;
                  console.log('‚úÖ Taille apr√®s compression:', (blob.size / 1024 / 1024).toFixed(2), 'MB');
                }
              }, 'image/jpeg', 0.90);  // üîß Qualit√© fallback augment√©e √† 90%
            }

            // Convertir en Data URL pour l'affichage
            const reader = new FileReader();
            reader.onloadend = () => {
              const dataUrl = reader.result as string;

              // ‚úÖ CORRECTION CRITIQUE : Utiliser referenceId (qui est l'etapeID) comme ID de la photo
              const capturedPhoto: CapturedPhoto = {
                id: referenceId,  // ‚úÖ UTILISER L'ETAPEID DIRECTEMENT !
                pieceId,
                referencePhotoId: referenceId,
                blob,
                dataUrl,
                takenAt: new Date().toISOString(),
                meta: {
                  width: optimizedCanvas.width,
                  height: optimizedCanvas.height,
                  // üîç D√âTECTION DE FLOU : Ajouter les informations de nettet√© compl√®tes
                  isBlurry,
                  blurScore: parseFloat(blurScore.toFixed(2)),
                  blurStats: stats && typeof stats === 'object' && 'maxLaplacian' in stats ? {
                    maxLaplacian: stats.maxLaplacian,
                    pixelCount: stats.pixelCount,
                    threshold: stats.threshold,
                    minVariance: stats.minVariance,
                    confidence: stats.confidence
                  } : undefined
                }
              };

              console.log('‚úÖ Photo captur√©e avec succ√®s:', {
                id: capturedPhoto.id,
                etapeID: referenceId,
                size: (blob.size / 1024).toFixed(2) + ' KB',
                dimensions: `${optimizedCanvas.width}x${optimizedCanvas.height}`,
                // üîç D√âTECTION DE FLOU : Afficher les stats d√©taill√©es
                ...(stats && {
                  'üîç Blur Detection': {
                    isBlurry,
                    blurScore: parseFloat(blurScore.toFixed(2)),
                    confidence: `${stats.confidence?.toFixed(1) || 0}%`,
                    maxLaplacian: stats.maxLaplacian?.toFixed(2)
                  }
                })
              });

              // Sauvegarder dans le state
              setCapturedPhotos(prev => {
                const newMap = new Map(prev);
                newMap.set(referenceId, capturedPhoto);
                return newMap;
              });

              resolve(capturedPhoto);
            };

            reader.onerror = () => {
              reject(new Error('Erreur lors de la conversion en Data URL'));
            };

            reader.readAsDataURL(blob);
          } catch (error) {
            reject(error);
          }
        }, 'image/jpeg', quality);

      } catch (error) {
        console.error('‚ùå Erreur lors de la capture:', error);
        reject(error);
      }
    });
  }, [pieceId]);

  const removePhoto = useCallback((referenceId: string) => {
    console.log('üóëÔ∏è Suppression photo pour r√©f√©rence:', referenceId);
    setCapturedPhotos(prev => {
      const newMap = new Map(prev);
      const photo = newMap.get(referenceId);
      
      if (photo) {
        // Lib√©rer la m√©moire du blob si possible
        if (photo.blob && 'stream' in photo.blob) {
          try {
            (photo.blob as any).stream().cancel();
          } catch (e) {
            // Ignore les erreurs de nettoyage
          }
        }
        
        newMap.delete(referenceId);
        console.log('‚úÖ Photo supprim√©e');
      }
      
      return newMap;
    });
  }, []);

  const clearAllPhotos = useCallback(() => {
    console.log('üßπ Suppression de toutes les photos captur√©es');
    
    // Lib√©rer la m√©moire de tous les blobs
    capturedPhotos.forEach(photo => {
      if (photo.blob && 'stream' in photo.blob) {
        try {
          (photo.blob as any).stream().cancel();
        } catch (e) {
          // Ignore les erreurs de nettoyage
        }
      }
    });
    
    setCapturedPhotos(new Map());
    console.log('‚úÖ Toutes les photos supprim√©es');
  }, [capturedPhotos]);

  const getCapturedPhotoForReference = useCallback((referenceId: string): CapturedPhoto | null => {
    return capturedPhotos.get(referenceId) || null;
  }, [capturedPhotos]);

  return {
    capturedPhotos,
    capturePhoto,
    removePhoto,
    clearAllPhotos,
    getCapturedPhotoForReference
  };
}


